#+TITLE: Project
#+AUTHOR: José Pires
#+DATE: [2021-10-19 ter 11:25]
#+EMAIL: a50178@alunos.uminho.pt

#+LATEX_COMPILER: xelatex
* Preamble
- This folder contains all the information about the project.
- It is written incrementally, i.e., as the several project phases take place,
  the document versions pertaining to each phase are stored in the folder
  *submission*.
* Versions [1/1]
1. [X] Problem statement: deadline - <2021-10-28 qui>

* Notes                                                           :Important:
  :PROPERTIES:
  :ID:       ea2d2209-c1f3-4de8-9acb-90bca065b262
  :END:
** Requirements
   - buildroot
   - c/c++ (both)
   - Device drivers
   - Linux/Raspberry Pi
   - CPS: Cyber-physical systems
   - Makefiles
** Problem statement
   DEADLINE: <2021-10-28 qui>
   Think about the project and deliver a document about it.
** Research
*** Topics [0/3]
 - [ ] Cyber-physical systems characteristics: _identify the required features
   for the system_
 - [ ] Analyze previous projects to understand what is feasible in terms of
   Real-time systems using device drivers with Raspberry Pi: _gives an overall
   idea of what can be achieved_
 - [ ] Situate the project requirements, the project constraints
*** Selection
- [[file:readme.org][Marketing digital Outdoor]]
** Report
*** Outline [1/7]
1. [X] Introduction
   1. Motivation and context
   2. Problem statement
   3. Market research
   4. Goals
   5. Project planning
   6. Report outline
2. [ ] Analysis
   1. Background and state of the art
   2. Requirements and constraints
   3. System overview
   4. System architecture
      1. HW architecture
      2. SW architecture
   5. Subsystems decomposition
      1. Events
      2. Use cases
      3. State machine diagram
      4. Sequence diagram
   6. Budget
   7. Theoretical foundations
3. [ ] Design
   1. HW specification
      1. Block diagram with COTS components, if possible
      2. List of constraints of functions to be implemented in HW or SW
   2. HW interfaces definition
      1. I/O ports
      2. HW registers
      3. Memory addresses for shared or I/O by memory mapping
      4. HW interrupts
   3. SW specification
      1. Identify main subsystems
      2. System tasks
   4. SW interfaces definition
      - Define the APIs in detail:
	- header files with:
	  - functions prototypes
	  - data structure declarations
	  - class declarations
   5. Start-up/shutdown process specification
   6. Error Handling specification
4. [ ] Implementation
5. [ ] Testing
6. [ ] Verification/Validation
7. [ ] Conclusions
** Marketing Digital Outdoor                                      :Important:
*** Topics
1. Motivation and context
   - Scenting marketing is a great approach to draw people into stores.
   - Scent sense is the fastest way to the brain, thus, providing an exceptional
     opportunity for marketing.
   - Combining that with additional stimuli, like eye and earing, can
     significantly boost the marketing outcome.
     #+begin_quote
   - Knowing your target audience it is critical for the success of stores.
   - Marketing can be used to collect, analyse, investigate and decide the best
     politics for addressing a specific target audience, understanding the
     its behavioral patterns. 
   - To understand behavioral patterns _machine-learning models_ can be used.
     #+end_quote
2. Concept
   - Offer a marketing digital outdoor for brands to advertise and captivate customers
   - Brands can buy advertisement space and time by sending the following data:
	| Digital Outdoor location | Fragrance name | Start Time | Stop Time | Audio Message | Video |
     - The brands can send the data to our company database through our
       website/application.
     - The data will then be sent to the marketing digital outdoor using a wireless
       communication technology.
   - The advertisement data will be exposed into a display, an audio message
     transmitted, as well as the indicate fragrance between the designated time
     interval.
   - COVID pandemics changed the perspectives about user interaction with the
     surroundings, with non touch interfaces being preferred. Thus, a non touch
     user interface is a must have.
   - When a user approaches the marketing digital outdoor, a proximity sensor will detect
     it and activate the _user interaction mode_.
     - When activating this mode the camera is started mirroring the user into
       the display and providing additional options.
     - In this mode, the user can:
       1) apply image filters related to the brand
       2) take pics
       3) create GIFs
       4) share them
     - This mode requires:
       - Facial detection for image filter application
       - Hand gesture recognition for navigating the menus and activating
         options
       - A virtual keyboard (non-touch) will be provided for user input, by
         mapping the screen to the keys and waiting for a designated time before
         accepting it.
       - A set of hand gestures to be used in user interaction
     - Several sharing platforms shall be provided namely social media and
       email.
       - Tracking the nr of shares provides feedback for the brands in respect
         of the brand awareness.
       - Additionally, brands can also monitor this by checking their social
         media accounts.
 
*** Technologies [0/11]
1. [ ] Computer vision for facial and gesture recognition (OpenCV)
2. [ ] Database for marketing digital outdoor management (SQL)
3. [ ] Website/Application for brands communication to our database
4. [ ] Wireless communication technology for remote communication with digital outdoors
5. [ ] Image filter application
6. [ ] Infrared detection
7. [ ] Camera recording
8. [ ] Audio output
9. [ ] Nebulizer technology for scenting
10. [ ] Screen mapping to keys for virtual keyboard
11. [ ] Social media and e-mail sharing APIs

*** ✔ DONE Problem statement
    :LOGBOOK:
    - State "✔ DONE"     from              [2021-10-23 sáb 11:55]
    :END:

*** ✔ DONE Market research [3/3]
    :LOGBOOK:
    - State "✔ DONE"     from              [2021-11-19 sex 23:30]
    :END:
1) [X] Scenting marketing: trends, market value
2) [X] Digital Outdoors: quantity, market value
3) [X] Combined marketing: are they digital outdoor + scenting?

*** Project planning
**** Gantt diagram [0/8]
1) [ ] Planning
   - [ ] Kick-off meeting
   - [ ] Problem Statement
   - [ ] Market Research
   - [ ] Project Planning
2) [ ] Analysis
   - [ ] System overview
   - [ ] Requirements and constraints
   - [ ] System architecture
   - [ ] System Analysis
   - [ ] Estimated budgets
   - [ ] Subsystem decomposition
     - [ ] Events
     - [ ] Use-cases
     - [ ] Dynamic operation: state-machine diagram
     - [ ] Flow of events: sequence diagram
3) [ ] Design
   - [ ] Analysis review
   - [ ] HW specification
   - [ ] Component shipping
   - [ ] Software specification
     - [ ] Remote client
     - [ ] Remote server + database
     - [ ] Local system
4) [ ] Implementation
   - [ ] HW testing
   - [ ] SW implementation
     - [ ] Remote client
     - [ ] Remote server + database
     - [ ] Local system
   - [ ] HW implementation
     - [ ] Breadboard
     - [ ] PCB design
   - [ ] System configuration
5) [ ] Testing
   1) [ ] SW unit testing
   2) [ ] SW integrated testing
   3) [ ] HW unit testing
   4) [ ] HW integrated testing
   5) [ ] Functional testing
6) [ ] Verification/Validation
   1) [ ] Verification
   2) [ ] Validation
7) [ ] Report Writing
   1) [ ] Problem statement
   2) [ ] Analysis
   3) [ ] Design
   4) [ ] Implementation
   5) [ ] Final
8) [ ] Documentation
   1) [ ] Problem statement
   2) [ ] Analysis
   3) [ ] Design
   4) [ ] Implementation
   5) [ ] Testing
**** Required HW [3/7]
Research link: https://www.one-tab.com/page/TZxmVAXJTO6nVyNO593ARA

- [X] Raspberry Pi 4: 52 EUR
- [X] HDMI screen: 50 EUR - https://shorturl.at/oyAOR 
- [ ] Relay/Transistor + Ultrassonic actuator for nebulizing fragrance
- [ ] Audio output
- [ ] Power supply
- [ ] Mechanical structure
- [X] Camera: 14 EUR - https://shorturl.at/gnpCU
*** Analysis
**** System architecture
*Example*
#+BEGIN_QUOTE
BRAND -> DB
RC -> RS: q brand Nestle
RS -> DB: query brand Nestle
DS -> RS: Nestle milka.mp4 milka.wav Chocolate
RS -> RC: Nestle milka.mp4 milka.wav Chocolate

COMPANY -> MDO-L
Staff member login
    RC -> RS: q mdo systems
    RS -> DB: query mdo-systems
    DB -> RS: std::<vector> mdo_systems
    for(i = 0; i < mdo_systems.size(); i++ )
        RS -> RC: mdo_systems[i]
RC -> RC: Select MDO-L machine
Send command
    RC -> RS: mdo <nr> <command> (mdo 1 get mode)
    RS -> RS: parse command
    RS -> RS: get mdo_nr IP (query mdo-systems 1 IP)
    RS -> MDO-L: connect IP:port
    MDO-L -> RS: connected
    RS -> MDO-L: get mode
    MDO-L -> RS: normal mode (example)
    RS -> RC: normal
#+END_QUOTE
*** Theoretical foundations [3/15]  
    :PROPERTIES:
    :ATTACH_DIR: /home/zmpl/OneDrive - Universidade do Minho/Univ/MI_Electro/Sem7/SEC/2021-22/repo/Proj/sec/img/
    :END:
1) [X] *Project methodology: Waterfall model*
2) [X] *Multitasking and Pthreads*
3) [X] *Client-Server architecture & TCP/IP & OSI model*
4) [ ] /Daemons/
5) [ ] /Device drivers/
6) [ ] *Nebulizer technology for scenting*
7) [-] *Computer Vision*
   1) [X] *OpenCV*
   2) [ ] *Gesture recognition algorithms*
   3) [X] *Face detection algorithms*
      1) see [[file:biblio/OpenCV3_Computer-Vision-in-C++-with-the-OpenCV-Library.pdf][openCV3 book]] (pg. 883)
8) [ ] *RDBMS (Relational Database management system) (SQL)*
9) [ ] /User detection technologies: IR, ultrasonic/
10) [ ] /Camera recording and codecs/
11) [ ] /Image filtering APIs/
12) [ ] /GIFs generation/
13) [ ] *Social media and e-mail sharing APIs*
14) [ ] /UI framework: Qt/
15) [ ] /File transfer protocols/

Legend:
- *Ze*
- /Hugo/

* Diagrams
Diagrams can be drawn using [2/2]:
- [X] draw.io
  - User mockups
  - State-machine
- [X] [[id:03c3f7e2-18cd-4956-ad92-13e4a6cc1e60][PlantUML]] (stored in Proj/diags/plantuml)
  - Sequence diagram
  - Class diagram
** PlantUML
   :PROPERTIES:
   :ID:       03c3f7e2-18cd-4956-ad92-13e4a6cc1e60
   :END:
[[https://plantuml.com/][PlantUML]] is a tool for quickly drawing diagrams from text based descriptions.
It is specially adequate for sequence diagrams, as draw.io is not very fluid.
*** Setup [0/6]
1) [ ] Download PlantUML from the [[https://sourceforge.net/projects/plantuml/files/plantuml.jar/download][website]]: =plantuml.jar=
2) [ ] Place the =plantuml.jar= file into a known directory and add it to the
   path
3) [ ] Write a diagram text file in an extension =.pu= (example input/test.pu) -
   check the user manual for this
4) [ ] Navigate to the =input= folder using cd
5) [ ] Generate the diagram from the terminal using:
    #+BEGIN_SRC bash
    java -jar plantuml.jar test.pu -o ../out java -jar plantuml.jar test.puput/
    #+END_SRC
6) [ ] Check the generate png file: =output/test.png=
*** Workflow [0/4]
1) [ ] Write a diagram text file in an extension =.pu= (example input/test.pu) -
   check the user manual for this
2) [ ] Navigate to the =input= folder using cd
3) [ ] Generate the diagram from the terminal using:
    #+BEGIN_SRC bash
    java -jar plantuml.jar test.pu -o ../output/
    #+END_SRC
4) [ ] Check the generate png file: =output/test.png=
*** Sequence diagrams
**** Declaring participants
If the keyword participant is used to declare a participant, more control on that participant is possible.

The order of declaration will be the (default) order of display.

Using these other keywords to declare participants will change the shape of the participant representation:
1) actor
2) boundary
3) control
4) entity
5) database
6) collections
7) queue

#+BEGIN_SRC plantuml :file diags/plantuml/seq-diag/examples/decl-partic.png :exports both
  ' title PlantUML (comment)
@startuml

participant Participant as Foo
actor       Actor       as Foo1
boundary    Boundary    as Foo2
control     Control     as Foo3
entity      Entity      as Foo4
database    Database    as Foo5
collections Collections as Foo6
queue       Queue       as Foo7
Foo -> Foo1 : To actor 
Foo -> Foo2 : To boundary
Foo -> Foo3 : To control
Foo -> Foo4 : To entity
Foo -> Foo5 : To database
Foo -> Foo6 : To collections
Foo -> Foo7: To queue

@enduml
#+END_SRC

#+RESULTS:
[[file:diags/plantuml/seq-diag/examples/decl-partic.png]]
**** Change arrow style
You can change arrow style by several ways:
1) add a final x to denote a lost message
2) use \ or / instead of < or > to have only the bottom or top part of the arrow
3) repeat the arrow head (for example, >> or //) head to have a thin drawing
4) use -- instead of - to have a dotted arrow
5) add a final "o" at arrow head
6) use bidirectional arrow <->

#+BEGIN_SRC plantuml :file diags/plantuml/seq-diag/examples/arrow-style.png :exports both
@startuml
' comments as needed
' lost message
Bob ->x Alice 
' sync message
Bob -> Alice 
' async message
Bob ->> Alice
Bob -\ Alice
Bob \\- Alice
Bob //-- Alice

Bob ->o Alice
Bob o\\-- Alice

' bidirectional message
Bob <-> Alice
Bob <->o Alice
@enduml
#+END_SRC

#+RESULTS:
[[file:diags/plantuml/seq-diag/examples/arrow-style.png]]

**** Grouping messages
([[https://plantuml.com/sequence-diagram#425ba4350c02142c][src]])

It is possible to group messages together using the following keywords:
1) alt/else
2) opt
3) loop
4) par
5) break
6) critical
7) group, followed by a text to be displayed

It is possible to add a text that will be displayed into the header (for group,
see next paragraph 'Secondary group label').

The end keyword is used to close the group.

Note that it is possible to nest groups. 

#+BEGIN_SRC plantuml :file diags/plantuml/seq-diag/examples/group-msg.png :exports both
  ' title PlantUML (comment)
@startuml
Alice -> Bob: Authentication Request

alt successful case

    Bob -> Alice: Authentication Accepted

else some kind of failure

    Bob -> Alice: Authentication Failure
    group My own label
    Alice -> Log : Log attack start
        loop 1000 times
            Alice -> Bob: DNS Attack
        end
    Alice -> Log : Log attack end
    end

else Another type of failure

   Bob -> Alice: Please repeat

end
@enduml
#+END_SRC

#+RESULTS:
[[file:diags/plantuml/examples/seq-diag/group-msg.png]]
**** Notes on messages
It is possible to put notes on message using the note left or note right keywords just after the message.

You can have a multi-line note using the end note keywords. 

#+BEGIN_SRC plantuml :file diags/plantuml/seq-diag/examples/notes-msgs.png :exports both
@startuml
Alice->Bob : hello
note left: this is a first note

Bob->Alice : ok
note right: this is another note

Bob->Bob : I am thinking
note left
a note
can also be defined
on several lines
end note
@enduml
#+END_SRC

#+RESULTS:
[[file:diags/plantuml/seq-diag/examples/notes-msgs.png]]

**** Divider or separator
 If you want, you can split a diagram using == separator to divide your diagram
 into logical steps. 

#+BEGIN_SRC plantuml :file diags/plantuml/seq-diag/examples/divider.png :exports both
@startuml

== Initialization ==

Alice -> Bob: Authentication Request
Bob --> Alice: Authentication Response

== Repetition ==

Alice -> Bob: Another authentication Request
Alice <-- Bob: another authentication Response

@enduml
#+END_SRC

#+RESULTS:
[[file:diags/plantuml/seq-diag/examples/divider.png]]

**** Lifeline activation and destruction
The =activate= and =deactivate= are used to denote participant activation.

Once a participant is activated, its lifeline appears.

The activate and deactivate apply on the previous message.

The =destroy= denote the end of the lifeline of a participant. 

#+BEGIN_SRC plantuml :file diags/plantuml/seq-diag/examples/lifeline.png :exports both
@startuml
participant User

User -> A: DoWork
activate A

A -> B: << createRequest >>
activate B

B -> C: DoWork
activate C
C --> B: WorkDone
destroy C

B --> A: RequestCreated
deactivate B

A -> User: Done
deactivate A

@enduml
#+END_SRC

#+RESULTS:
[[file:diags/plantuml/seq-diag/examples/lifeline.png]]

**** Participant creation
 You can use the =create= keyword just before the first reception of a message
 to emphasize the fact that this message is actually creating this new object. 

#+BEGIN_SRC plantuml :file diags/plantuml/seq-diag/examples/partic-creation.png :exports both
@startuml
Bob -> Alice : hello

create Other
Alice -> Other : new

create control String
Alice -> String
note right : You can also put notes!

Alice --> Bob : ok

@enduml
#+END_SRC

#+RESULTS:
[[file:diags/plantuml/seq-diag/examples/partic-creation.png]]

**** Incoming and outgoing messages
You can use incoming or outgoing arrows if you want to focus on a part of the diagram.

Use square brackets to denote the left "[" or the right "]" side of the
diagram. 

#+BEGIN_SRC plantuml :file diags/plantuml/seq-diag/examples/in-out-msgs.png :exports both
@startuml
[-> A: DoWork

activate A

A -> A: Internal call
activate A

A ->] : << createRequest >>

A<--] : RequestCreated
deactivate A
[<- A: Done
deactivate A
@enduml
#+END_SRC

#+RESULTS:
[[file:diags/plantuml/seq-diag/examples/in-out-msgs.png]]

**** Anchors and duration
 With =teoz= it is possible to add anchors to the diagram and use the anchors to
 specify duration time. 

#+BEGIN_SRC plantuml :file diags/plantuml/seq-diag/examples/anchors-duration.png :exports both
@startuml
!pragma teoz true

{start} Alice -> Bob : start doing things during duration
Bob -> Max : something
Max -> Bob : something else
{end} Bob -> Alice : finish

{start} <-> {end} : some time

@enduml
#+END_SRC

#+RESULTS:
[[file:diags/plantuml/seq-diag/examples/anchors-duration.png]]


You can use the -Pcommand-line option to specify the pragma:
#+BEGIN_SRC bash
java -jar plantuml.jar -Pteoz=true
#+END_SRC

**** Participants encompass
It is possible to draw a box around some participants, using box and end box commands.

You can add an optional title or a optional background color, after the box
keyword. 

#+BEGIN_SRC plantuml :file diags/plantuml/seq-diag/examples/partic-encompass.png :exports both
@startuml

box "Internal Service" #LightBlue
participant Bob
participant Alice
end box
participant Other

Bob -> Alice : hello
Alice -> Other : hello

@enduml
#+END_SRC

#+RESULTS:
[[file:diags/plantuml/seq-diag/examples/partic-encompass.png]]


**** Remove foot boxes
      You can use the =hide footbox= keywords to remove the foot boxes of the
      diagram. 

#+BEGIN_SRC plantuml :file diags/plantuml/seq-diag/examples/remove-foot-box.png :exports both
@startuml

hide footbox
title Foot Box removed

Alice -> Bob: Authentication Request
Bob --> Alice: Authentication Response

@enduml
#+END_SRC

#+RESULTS:
[[file:diags/plantuml/seq-diag/examples/remove-foot-box.png]]

**** Style =strictuml=
To be conform to strict UML (for arrow style: emits triangle rather than sharp
arrowheads), you can use: 

#+BEGIN_SRC plantuml :file diags/plantuml/seq-diag/examples/strict-uml.png :exports both
@startuml
skinparam style strictuml
Bob -> Alice : hello
Alice -> Bob : ok
@enduml
#+END_SRC

#+RESULTS:
[[file:diags/plantuml/seq-diag/examples/strict-uml.png]]

**** Color a group message
It is possible to color a group message: 
#+BEGIN_SRC plantuml :file diags/plantuml/seq-diag/examples/color-group-msg.png :exports both
@startuml
Alice -> Bob: Authentication Request
alt#Gold #LightBlue Successful case
    Bob -> Alice: Authentication Accepted
else #Pink Failure
    Bob -> Alice: Authentication Rejected
end
@enduml
#+END_SRC

#+RESULTS:
[[file:diags/plantuml/seq-diag/examples/color-group-msg.png]]

**** Colors
You can use specify *fill* and *line* colors either:
1. with its standard name or CSS name
2. using HEX value (6 digits): #RRGGBB
3. using HEX value (8 digits) with alpha compositing or RGBA color model:
   #RRGGBBaa
4. using short HEX value (3 digits): #RGB

#+BEGIN_SRC plantuml :file diags/plantuml/seq-diag/examples/colors.png :exports both
@startuml
actor Bob #Red/Yellow
actor Alice #FF0000/FFFF00
Alice -> Bob : hello
@enduml
#+END_SRC

#+RESULTS:
[[file:diags/plantuml/seq-diag/examples/colors.png]]
**** All together                                                 :Important:
This example tries to combine all the most important tips stated previously.

#+BEGIN_SRC plantuml :file diags/plantuml/seq-diag/examples/all-together.png :exports both
@startuml
' ---------- SETUP ----------------
' strict uml style and hide footboxes
skinparam style strictuml
hide footbox
' for anchors and duration this may be required (uncomment)
' !pragma teoz true


' ---------- Declaring participants
participant Participant as Foo
actor       Actor       as Foo1
boundary    Boundary    as Foo2
control     Control     as Foo3
entity      Entity      as Foo4
database    Database    as Foo5
collections Collections as Foo6
queue       Queue       as Foo7
Foo -> Foo1 : To actor 
Foo -> Foo2 : To boundary
Foo -> Foo3 : To control
Foo -> Foo4 : To entity
Foo -> Foo5 : To database
Foo -> Foo6 : To collections
Foo -> Foo7: To queue

' -------- Grouping messages ------------------
' divider or separator
' Encompass actors
' add colors to cases
' add notes
== Initialization ==

box "Internal Service" #LightBlue
participant Bob
participant Alice
end box
Alice -> Bob: Authentication Request
alt#Gold #LightBlue Successful case
    Bob -> Alice: Authentication Accepted
    note left: this is a first note
else #Pink Failure
    Bob -> Alice: Authentication Rejected
    note right: this is a 2nd note
end

== Repetition ==

Alice -> Bob: Another authentication Request
Alice <-- Bob: another authentication Response


Alice -> Bob: Authentication Request

alt successful case

    Bob -> Alice: Authentication Accepted

else some kind of failure

    Bob -> Alice: Authentication Failure
    group My own label
    Alice -> Log : Log attack start
        loop 1000 times
            Alice -> Bob: DNS Attack
        end
    Alice -> Log : Log attack end
    end

else Another type of failure

   Bob -> Alice: Please repeat

' ---------- Anchors and duration
{start} Alice -> Bob : start doing things during duration
Bob -> Max : something
Max -> Bob : something else
{end} Bob -> Alice : finish

{start} <-> {end} : some time

' --------- Incoming and outgoing messages
[-> A: DoWork

activate A

A -> A: Internal call
activate A

A ->] : << createRequest >>

A<--] : RequestCreated
deactivate A
[<- A: Done
deactivate A

' -------  Participant creation ---------
Bob -> Alice : hello

create Other
Alice -> Other : new

create control String
Alice -> String
note right : You can also put notes!

Alice --> Bob : ok

'-------- Lifeline activation/deactivation
participant User

User -> A: DoWork
activate A

A -> B: << createRequest >>
activate B

B -> C: DoWork
activate C
C --> B: WorkDone
destroy C

B --> A: RequestCreated
deactivate B

A -> User: Done
deactivate A

@enduml
#+END_SRC

#+RESULTS:
[[file:diags/plantuml/seq-diag/examples/all-together.png]]
**** Mine (to generate report)                           :noexport:Important:
     :PROPERTIES:
     :ID:       6e44c5fa-06a8-40bb-bef2-b1fbca2964fb
     :END:

*Interaction mode*
#+BEGIN_SRC plantuml :file diags/plantuml/seq-diag/output/seq-local-interaction-mode.png
  @startuml
  ' ---------- SETUP ----------------
  ' strict uml style and hide footboxes
  skinparam style strictuml
  hide footbox
  ' for anchors and duration this may be required (uncomment)
  ' !pragma teoz true

  ' ---------- Declaring participants
  ' participant Participant as Foo
  actor User
  box "MDO-L" #LightBlue
  boundary "Gesture Recognition Engine" as GRE
  control "UI Engine" as UIE
  actor "Local System \nBack-End" as LS
  endbox
  ' entity      Entity      as Foo4
  ' database    Database    as Foo5
  ' collections Collections as Foo6
  ' queue       Queue       as Foo7
  ' Foo -> Foo1 : To actor 
  ' Foo -> Foo2 : To boundary
  ' Foo -> Foo3 : To control
  ' Foo -> Foo4 : To entity
  ' Foo -> Foo5 : To database
  ' Foo -> Foo6 : To collections
  ' Foo -> Foo7: To queue

  ' async message
  == Activate camera feed ==
  User ->> LS: User in range
  activate User
  activate LS
  LS -> LS: activate camera

  par
    loop while (user in range && ! user_timeout)
	LS -> UIE: grab frame from camera and display it on window
	activate UIE
	UIE -> User: visual feedback
    end
    == Identify User gesture ==
    User ->> GRE: gesture
    activate GRE
    GRE -> LS: gesture recognized
    deactivate GRE
    LS -> LS: process gesture callback
    == Multimedia mode ==
    alt Select Image Filter
    LS -> UIE: show Image Filter view
    UIE -> User: visual feedback
    ref over User, GRE, UIE, LS: Image Filter
' -------
    else Take Pic
    LS -> UIE: show Pic view
    UIE -> User: visual feedback
    ref over User, GRE, UIE, LS: Picture mode
' -------
    else Create GIF
    LS -> UIE: show GIF view
    UIE -> User: visual feedback
    ref over User, GRE, UIE, LS: GIF mode
    '' LS -> LS: process gesture \ncallback
    '' LS -> UIE: provide output
    '' UIE -> User: visual feedback
    ' end alt
    end 
' end par
  end
		

  @enduml
#+END_SRC

#+RESULTS:
[[file:diags/plantuml/seq-diag/output/seq-local-interaction-mode.png]]

*Remote client*
#+BEGIN_SRC plantuml :file diags/plantuml/seq-diag/output/seq-rc.png
  @startuml
  ' ---------- SETUP ----------------
  ' strict uml style and hide footboxes
  skinparam style strictuml
  hide footbox
  ' for anchors and duration this may be required (uncomment)
  ' !pragma teoz true

  ' ---------- Declaring participants
  ' participant Participant as Foo
  
  actor User
  box "MDO-RC" #LightBlue
  boundary "UI" as UI
  control "UI Engine" as UIE
  actor "Remote Client \nBack-End" as RC
  endbox
  box "MDO-RS" #f9db8f
  actor "Remote Server" as RS
  database "User DB" as UserDB
  endbox
  ' entity      Entity      as Foo4
  ' database    Database    as Foo5
  ' collections Collections as Foo6
  ' queue       Queue       as Foo7

  ' async message
  == Application start ==
  activate User
  User ->> UI: starts app 
  deactivate User
  activate UI
  UI -> User: Show Login view
  deactivate UI
  activate User
''
  == Login ==
  activate User
  User ->> UI: input username and password
  UI -> User: visual feedback
  User ->> UI: User presses Login
''
  deactivate User
  activate UI
  UI -> UIE: login_btn_pressed
  deactivate UI
  activate UIE
  UIE -> RC : login(username, pass)
  deactivate UIE
  activate RC
  RC -> RC : Encrypt password
  RC ->> RS : send(username, pass_crypt)
  RS -> UserDB : transaction(username, pass_crypt)
'' DB transaction
  alt transaction success
    UserDB -> RS: User info
    RS ->> RC: User info
    RC -> RC: check type of User
    alt Admin user
    RC -> UIE: admin user
    UIE -> UI: admin_view
    UI -> User: Show admin view
    ref over RC, UIE, UI, User: Admin
    else Brand user
    RC -> UIE: brand user
    UIE -> UI: brand_view
    UI -> User: Show brand view
    ref over RC, UIE, UI, User: Brand
    end
  else failure
  UserDB -> RS: empty
  end
''
''  == User Authentication ==
''  alt Admin
''    UIE ->> RC : Send DBs relative to admin
''    RC ->> User : Show Main Menu
''    alt Users
''      User ->> RC : Manage Useres
''      RC ->> UIE : Send changes
''      UIE ->> UIE : Update data
''    else Statistics
''      User ->> RC : Watch Statistics
''      RC ->> User : Show Statistics
''    else Ads To Activate
''      User ->> RC : Download Videos, Accept/Deny Ads
''      RC ->> UIE : Send Changes
''      UIE ->> UIE : Update data
''    else Logout
''      User ->> RC : Logout
''      RC ->> RC : Quit
''    end
'    
''  else Brand
''    UIE ->> RC : Sends DBs relative to the brand 
''    RC ->> User : Show Main Menu
''    alt Notifications
''      User ->> RC : See notifications
''      RC ->> User : Show notifications
''    else Rented
''      User ->> RC : See Rented Ads
''      RC ->> User : Show statistics of Rented Ads
''    else To Rent
''      User ->> RC : Upload Videos, choose conditions and fragrancy
''      RC ->> UIE : Send Changes
''      UIE ->> UIE : Update data
''    else Logoudat
''      User ->> RC : Logout
''      RC ->> RC : Quit
''    end
''  end

' =========================== ZE das couves ==============================='
'  LS -> UIE: show Image Filter view
'  UIE -> User: visual feedback
'  ref over User, GRE, UIE, LS: Image Filter
' -------
'    else Take Pic
'    LS -> UIE: show Pic view
'    UIE -> User: visual feedback
'    ref over User, GRE, UIE, LS: Picture mode
' -------
'    else Create GIF
'    LS -> UIE: show GIF view
'    UIE -> User: visual feedback
'    ref over User, GRE, UIE, LS: GIF mode
'    '' LS -> LS: process gesture \ncallback
'    '' LS -> UIE: provide output
'    '' UIE -> User: visual feedback
'    ' end alt
'    end 
' end par
'  end
		

  @enduml
#+END_SRC

#+RESULTS:
[[file:diags/plantuml/seq-diag/output/seq-rc.png]]

*Normal mode*
#+BEGIN_SRC plantuml :file diags/plantuml/seq-diag/output/seq-local-normal-mode.png
  @startuml
  ' ---------- SETUP ----------------
  ' strict uml style and hide footboxes
  skinparam style strictuml
  hide footbox
  ' for anchors and duration this may be required (uncomment)
  ' !pragma teoz true

  ' ---------- Declaring participants
  ' participant Participant as Foo
  ''actor User
  box "MDO-L" #LightBlue
  ''boundary "Gesture Recognition Engine" as GRE
  ''control "UI Engine" as UIE
  actor "Local System Back-End" as LS
  endbox
  ' entity      Entity      as Foo4
  ' database    Database    as Foo5
  ' collections Collections as Foo6
  ' queue       Queue       as Foo7

  ' async message
  activate LS
  LS -> LS: Ads time
  LS -> LS: get video, audio and fragrance from internal DB
  par
  == Video playback ==
    loop while (! ads_time_stop)
	LS -> LS: get next video from videos playback queue
	LS -> LS: play video
    end
    == Fragrance diffusion ==
    loop while(1)
	LS -> LS: diffuse := (get next start and stop times)
	alt if(! diffuse)
	  break
	  end
	else diffuse
	  loop while(1)
	    alt if(start_time)
	      LS -> LS: start diffusion
	    else if(stop_time)
	      LS -> LS: stop diffusion
	    else idle
	      LS -> LS: sleep
	      'end alt
	    end
	    ' end while(1)
	  end
	  'end diffuse'
	end
    end
' end par
  end
		

  @enduml
#+END_SRC

#+RESULTS:
[[file:diags/plantuml/seq-diag/output/seq-local-normal-mode.png]]

*Multimedia mode: Select filter*
#+BEGIN_SRC plantuml :file diags/plantuml/seq-diag/output/seq-local-multimedia-mode-sel-filt.png
  @startuml
  ' ---------- SETUP ----------------
  ' strict uml style and hide footboxes
  skinparam style strictuml
  hide footbox
  ' for anchors and duration this may be required (uncomment)
  ' !pragma teoz true

  ' ---------- Declaring participants
  ' participant Participant as Foo
  actor User
  box "MDO-L" #LightBlue
  boundary "Gesture Recognition Engine" as GRE
  control "UI Engine" as UIE
  actor "Local System Back-End" as LS
  endbox
  actor "Image Filtering APIs" as IFA
  ' entity      Entity      as Foo4
  ' database    Database    as Foo5
  ' collections Collections as Foo6
  ' queue       Queue       as Foo7

  ' async message
''== Image filter ==
activate User
User ->> GRE: select filter gesture
deactivate User
activate GRE
GRE -> UIE: select filter gesture recognized
deactivate GRE
activate UIE
UIE -> LS: select_filt
deactivate UIE
activate LS
LS -> LS: apply_facial_detection
LS -> LS: sel_filt(filt)
group Apply filter
    loop while (! filter_cancel && ! filter_accept)
    ''ref over LS, IFA, UIE, User: apply filter
	LS -> IFA: filter_selected
	deactivate LS
	activate IFA
	IFA ->> LS: apply filter
	deactivate IFA
	activate LS
	LS -> UIE: filter applied
	deactivate LS
	activate UIE
	UIE -> User: show filter applied
	deactivate UIE
	activate User
    end
end
alt filter_accept
    activate User
    User ->> GRE: accept filter gesture
    deactivate User
    activate GRE
    GRE -> UIE: accept filter gesture recognized
    deactivate GRE
    activate UIE
    UIE -> LS: filter_accepted
    deactivate UIE
    activate LS
    LS -> LS: apply filter
    deactivate LS
    par
    ref over User, IFA: Interaction mode
    ref over User, IFA: Apply filter
    end
else filter_cancel
    activate User
    User ->> GRE: cancel filter gesture
    deactivate User
    activate GRE
    GRE -> UIE: cancel filter gesture recognized
    deactivate GRE
    activate UIE
    UIE -> LS: filter_canceled
    deactivate UIE
    activate LS
    LS -> LS: cancel filter
    deactivate LS
    ref over User, LS: Interaction mode
end
  @enduml
#+END_SRC

#+RESULTS:
[[file:diags/plantuml/seq-diag/output/seq-local-multimedia-mode-sel-filt.png]]

*Multimedia mode: Take pic*
#+BEGIN_SRC plantuml :file diags/plantuml/seq-diag/output/seq-local-multimedia-mode-take-pic.png
  @startuml
  ' ---------- SETUP ----------------
  ' strict uml style and hide footboxes
  skinparam style strictuml
  hide footbox
  ' for anchors and duration this may be required (uncomment)
  ' !pragma teoz true

  ' ---------- Declaring participants
  ' participant Participant as Foo
  actor User
  box "MDO-L" #LightBlue
  boundary "Gesture Recognition Engine" as GRE
  control "UI Engine" as UIE
  actor "Local System Back-End" as LS
  endbox
''  actor "Image Filtering APIs" as IFA
  ' entity      Entity      as Foo4
  ' database    Database    as Foo5
  ' collections Collections as Foo6
  ' queue       Queue       as Foo7

  ' async message
''== Take Pic ==
[->> LS: Picture mode initiated
activate LS
LS -> LS: Start pic timer
loop while (! pic_timer_elapsed)
    LS -> UIE: time_remaining
    deactivate LS
    activate UIE
    UIE -> User: show time remaining
    deactivate UIE
    activate User
end
deactivate User
activate LS
LS -> LS: store picture
deactivate LS
  @enduml
#+END_SRC

#+RESULTS:
[[file:diags/plantuml/seq-diag/output/seq-local-multimedia-mode-take-pic.png]]

*Multimedia mode: Create GIF*
#+BEGIN_SRC plantuml :file diags/plantuml/seq-diag/output/seq-local-multimedia-mode-create-gif.png
  @startuml
  ' ---------- SETUP ----------------
  ' strict uml style and hide footboxes
  skinparam style strictuml
  hide footbox
  ' for anchors and duration this may be required (uncomment)
  ' !pragma teoz true

  ' ---------- Declaring participants
  ' participant Participant as Foo
  actor User
  box "MDO-L" #LightBlue
  boundary "Gesture Recognition Engine" as GRE
  control "UI Engine" as UIE
  actor "Local System Back-End" as LS
  endbox
''  actor "Image Filtering APIs" as IFA
  ' entity      Entity      as Foo4
  ' database    Database    as Foo5
  ' collections Collections as Foo6
  ' queue       Queue       as Foo7

  ' async message
''== Create GIF ==
[->> LS: GIF mode initiated
activate LS
LS -> LS: Start GIF setup timer
loop while (! gif_setup_timer_elapsed)
    LS -> UIE: time_remaining
    deactivate LS
    activate UIE
    UIE -> User: show time remaining
    deactivate UIE
    activate User
end
deactivate User
LS -> LS: Start GIF operation timer
loop while (! gif_oper_timer_elapsed)
    LS -> UIE: time_remaining
    deactivate LS
    activate UIE
    UIE -> User: show time remaining in a dial
    deactivate UIE
    activate User
end
deactivate User
activate LS
LS -> LS: store GIF
deactivate LS
  @enduml
#+END_SRC

#+RESULTS:
[[file:diags/plantuml/seq-diag/output/seq-local-multimedia-mode-create-gif.png]]

*Sharing mode*
#+BEGIN_SRC plantuml :file diags/plantuml/seq-diag/output/seq-local-sharing-mode.png
  @startuml
  ' ---------- SETUP ----------------
  ' strict uml style and hide footboxes
  skinparam style strictuml
  hide footbox
  ' for anchors and duration this may be required (uncomment)
  ' !pragma teoz true

  ' ---------- Declaring participants
  ' participant Participant as Foo
  actor User
  box "MDO-L" #LightBlue
  boundary "Gesture Recognition Engine" as GRE
  control "UI Engine" as UIE
  actor "Local System Back-End" as LS
  endbox
  actor "Social Media Servers" as SMS
''  actor "Image Filtering APIs" as IFA
  ' entity      Entity      as Foo4
  ' database    Database    as Foo5
  ' collections Collections as Foo6
  ' queue       Queue       as Foo7

  ' async message
''== Sharing mode ==
== Social media selection ==
activate User
User ->> GRE: select SM gesture
deactivate User
activate GRE
GRE -> UIE: select SM gesture recognized
deactivate GRE
activate UIE
UIE -> LS: sm_selected(sm)
deactivate UIE
activate LS
LS -> LS: configure SM platform
LS -> LS: attachment = last multimedia file
LS -> UIE: post_edit
deactivate LS
activate UIE
UIE -> User: show Post Edit view
deactivate UIE
activate User
''deactivate User
== Post editing ==
loop while ( !share_post && !share_cancel)
    ''activate User
    User -> GRE: character selected gesture
    deactivate User
    activate GRE
    GRE -> UIE: char selected gesture recognized
    deactivate GRE
    activate UIE
    UIE -> UIE: get_input(char)
    UIE -> User: show feedback
    deactivate UIE
    activate User
end
== Share decision ==
alt share_post
    activate User
    User ->> GRE: share post gesture
    deactivate User
    activate GRE
    GRE -> UIE: share post gesture recognized
    deactivate GRE
    activate UIE
    UIE -> LS: post_share(message)
    deactivate UIE
    ref over User, LS: share_post
else share_cancel
    activate User
    User ->> GRE: cancel post gesture
    deactivate User
    activate GRE
    GRE -> UIE: cancel post gesture recognized
    deactivate GRE
    activate UIE
    UIE -> LS: cancel_share
    deactivate UIE
    ref over User, LS: interaction mode
    ''activate LS
end
''deactivate User
== Share Post ==
group share_post
''activate LS
LS -> LS ++: share_post(SM, message, attachment)
LS ->> SMS: login
deactivate LS
activate SMS
return login_status
deactivate SMS
activate LS
alt if (login_status == fail)
    ref over LS, SMS: share_fail
    else success
    LS ->> SMS: post_status = send(message, attachment)
    deactivate LS
    activate SMS
    return post_status
    activate LS
    alt if(post_status == fail)
	ref over LS, SMS: share_fail
	deactivate LS
    end
end
alt share_success
    activate LS
    LS -> UIE: share_success
    deactivate LS
    activate UIE
    UIE -> User: show Share Success view
    deactivate UIE
else share_fail
    activate LS
    LS -> UIE: share_fail
    deactivate LS
    activate UIE
    UIE -> User: show Share Failure view
    deactivate UIE
    activate User
end
end
  @enduml
#+END_SRC

#+RESULTS:
[[file:diags/plantuml/seq-diag/output/seq-local-sharing-mode.png]]
* Gesture recognition                                              :noexport:
** Research [0/6]
1) [ ] [[https://techvidvan.com/tutorials/hand-gesture-recognition-tensorflow-opencv/][Real-time Hand Gesture Recognition using TensorFlow & OpenCV]]
   1) MediaPipe: a customizable ML frameworks developed by Google which
      comes with some pre-trained models such as face detection and object
      recognition
      1) Recognize hand and the hand key points
   2) TensorFlow: neural networks for ML and DL
      1) These keypoints are fed into a pre-trained gesture recognizer network
	 to recognize the hand pose
   3) Steps:
      1) Import necessary packages.
      2) Initialize models.
      3) Read frames from a webcam.
      4) Detect hand keypoints.
      5) Recognize hand gestures.
2) [ ] [[https://gogul.dev/software/hand-gesture-recognition-p1][Hand gesture recognition using Python and OpenCV]]
   1) Background segmentation
   2) Motion detection and thresholding
   3) Contour extraction
3) [ ] [[file:~/OneDrive%20-%20Universidade%20do%20Minho/Univ/MI_Electro/Sem7/SEC/2021-22/repo/research/gesture-recognition/Hand_gesture_recognition_on_python_and_opencv.pdf][Hand gesture recognition on python and openCV (overview)]]
   1) Hand segmentation
   2) Track gesture of hand using Haar-Cascade Classifier
   3) Region of Interest
   4) Convex-Hull Transform
4) [ ] [[https://github.com/mahaveerverma/hand-gesture-recognition-opencv][Hand gesture recognition in Python using openCV]]
   1) Background subtraction
   2) Histogram
   3) Threshold
   4) Contour and convex hull
      #+BEGIN_EXAMPLE
During setup, first a background model is generated when the user presses 'b'. Then, a histogram is generated when the user provides his hand as a sample by pressing 'c'. When the setup is completed, the program goes into an infinite while loop which does as follows.

Camera input frame is saved to a numpy array. A mask is generated based on background model and applied on the frame. This removes background from the captured frame. Now the frame containing only the foreground is converted to HSV color space, followed by histogram comparison (generating back projection). This leaves us with the detected hand. Morphology and smoothening is applied to get a proper hand shape out of the frame. A threshold converts this into a binary image.

Next, we find contours of the binary image obtained, look for the largest contour and find its convex hull.

Using points from the largest contour we determine center of the palm by finding the largest circle inscribed inside the contour and then the dimension of palm. Using the center of palm as reference, we eliminate all points from the convex hull which do not seem to be part of hand. Also, nearby convex hull points are eliminated so that we are left with exactly only those many points as the number of fingers stretched out.

Using the positions of fingers and palm dimensions, we model our hand.

Then we compare the model with a dictionary of Gestures defined in GestureAPI.py to determine presence of gestures.
      #+END_EXAMPLE
5) [ ] [[https://towardsdatascience.com/training-a-neural-network-to-detect-gestures-with-opencv-in-python-e09b0a12bdf1][Training a Neural Network to Detect Gestures with OpenCV in Python]]
   1) [[https://docs.google.com/presentation/d/1UY3uWE5sUjKRfV7u9DXqY0Cwk6sDNSalZoI2hbSD1o8/edit#slide=id.g49b784d7df_0_2205][Presentation (Summary)]]
6) [ ] [[https://circuitdigest.com/microcontroller-projects/hand-gesture-recognition-using-raspberry-pi-and-opencv][Hand Gesture Recognition using Raspberry Pi and OpenCV]] 
