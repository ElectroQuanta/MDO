%
\section{Computer vision}
\label{sec:computer-vision}
Computer vision is a vast field, but can broadly be defined as the
transformation of data from a still image or video camera into
either a decision or a new representation to achieve some particular goal~\cite{kaehler2016learning}.

The input data may include some contextual information
such as `the camera is mounted in a car' or `laser range finder indicates an
object is 1 meter away.'
The decision might be `there is a person in this scene' or `there are 14
tumor cells on this slide.'
A new representation might mean turning a color image
into a grayscale image or removing camera motion from an image
sequence~\cite{kaehler2016learning}.

In this section, computer vision frameworks/libraries are listed, with special
focus on OpenCV, and computer vision algorithms for face detection and hand
gesture recognition are analyzed.
%

\subsection{Computer vision frameworks}
\label{sec:comp-visi-fram}
There are several noteworthy computer vision frameworks, namely~\cite{cv-frameworks-2020}:
\begin{enum-c}
\item \emph{Google Cloud's Vision API}:
it is an easy-to-use image recognition technology that
lets developers understand the content of an image by applying powerful machine
learning models. It enables key vision
detection features within an application ---  face, and landmark
detection, image labeling, \gls{ocr}, and explicit
content tagging --- and image classification into millions of predefined
categories.
\item \emph{YOLOv3}:
YOLO (You Only Look Once) is a state-of-the-art, real-time object detection
system among the most widely used deep learning-based object detection methods. It considers object detection as a regression problem,
directly predicting the class probabilities and bounding box offsets from full
images with a single feed-forward \gls{cnn}.
YOLOv3 eliminates region proposal generation and feature
resampling and encapsulates all stages in a single network to form a true
end-to-end detection system.
\item \emph{TensorFlow}:
it is a free, open-source framework for creating algorithms to develop a
user-friendly Graphical Framework called TensorFlow Graphical Framework
(TF-GraF) for object detection API, which is widely applied to solve complex
tasks efficiently in agriculture, engineering, and medicine.
The TF-GraF provides independent virtual environments for amateurs and beginners
to design, train, and deploy machine intelligence models without coding or
\gls{cli} in the client-side.
\item \emph{libfacedetection}:
it is an open-source library for face detection in images. It uses a pre-trained
\gls{cnn}, enabling face detection on inputs with a size greater than 10×10
pixels. The source code is not dependant on any other libraries. A C++ compiler
is required to compile the source under various platforms, such as Windows,
Linux, ARM, etc..
\item \emph{Raster Vision}:
it is an open-source Python framework to build computer vision models on
satellite, aerial, and other large sets of images (including oblique drone
imagery), using deep learning or machine learning models.
It has built-in support for chip classification, object detection, and semantic
segmentation with backbends using PyTorch and Tensorflow.
The framework is also extensible to new data sources, tasks (e.g., object
detection), backend (e.g., TF Object Detection API), and cloud providers.
\item \emph{SOD}:
it is an embedded, modern cross-platform computer vision and machine learning
software library.
It exposes a set of APIs for deep-learning, advanced media analysis, and
processing, including real-time, multi-class object detection, and model
training on embedded systems with limited computational resource and \gls{iot}
devices.
Designed for computational efficiency and with a strong focus on real-time
applications, SOD includes a comprehensive set of both classic and
state-of-the-art deep-neural networks with their pre-trained models.
Although it is open source, the pre-trained models are charged (one time fee
only -- up to 30 \gls{usd}).
\item \emph{Face\_recognition}:
  it is a facial recognition API for Python and the command line, built with
  deep learning using dlib60‘s state-of-the-art face recognition.
  The model has an accuracy of 99.38\% on the Labeled Faces in the Wild
  benchmark.
\item \emph{JeelizFaceFilter}:
it is a lightweight and robust face tracking library, designed for augmented reality face filters.
This JavaScript library can detect and track the face in real-time from the
webcam video feed captured, enabling the developers to solve computer-vision
problems directly from the browser.
The key features include face detection, face tracking, face rotation
detection, mouth opening detection, multiple face detection, and tracking, video
acquisition with \gls{hd} video ability, etc.
\item \emph{OpenCV}:
it is an open-source computer vision and machine learning software library,
built to provide a common infrastructure for computer vision applications and
accelerate the use of machine perception in commercial products.
OpenCV was designed for computational efficiency and with a strong focus on
real-time applications. It is written in optimized C++ and can take advantage of
multicore processors, with wrappers written in Python, Java, Matlab, etc., and
supporting Windows, Linux, Android and Mac OS.
The library has more than 2500 optimized algorithms, including a comprehensive
set of both classic and state-of-the-art computer vision and machine learning algorithms.
These algorithms can be used to detect and recognize faces, identify objects,
classify human actions in videos, track camera movements, track moving objects,
extract 3D models of objects and produce 3D point clouds from stereo cameras.
It can stitch images together to produce a high-resolution image of an entire
scene, find similar images from an image database, remove red eyes from images
taken using flash, follow eye movements, recognize scenery and establish markers to overlay it with augmented reality.
\end{enum-c}
%
%\subsubsection{OpenCV}
%\label{sec:opencv}
%
\subsection{Face detection}
\label{sec:face-detection}
Face detection has been studied for decades in the computer
vision literature. Modern face detection algorithms can be categorized into four categories~\cite{yang2016wider}:
cascade based methods, part based methods, channel feature based methods, and
neural network based methods. A detailed survey can be found in
~\cite{yang2002detecting, zhang2010survey}.

The seminal work by Viola and Jones~\cite{viola2004robust}
introduces integral image to compute Haar-like features in constant time.
These features are then used to learn AdaBoost classifier with cascade structure
for face detection.
Various later studies follow a similar pipeline, with SURF
cascade~\cite{li2013learning} achieving competitive performance.

Although the Viola-Jones are extremely fast, they require severe tunning to
prevent false-positives or complete misses.
In 2005, Dalal and Triggs~\cite{dalal2005histograms} demonstrated that the \gls{hog} image descriptor and
a Linear \gls{svm} could be used to train highly accurate object classifiers ---
or in their particular study, human detectors. However, due to the nature of
\gls{hog} that are only suited for frontal face detection as it is not invariant
to changes in rotation and viewing angle.

One of the well-known part based methods is \gls{dpm}~\cite{felzenszwalb2009object}. Deformable part
models define face as a collection of parts and model the connections
of parts through Latent \gls{svm}.
The part based methods are more robust to occlusion compared
with cascade-based methods.

\gls{acf} is first proposed by Dollar et al.~\cite{dollar2009pedestrian} to solve pedestrian detection.
Later on, Yang et al.~\cite{yang2014aggregate} applied this idea on face
detection. In particular, features such as gradient histogram, integral
histogram, and color channels are combined and used to learn boosting classifier
with cascade structure.

Recent studies~\cite{li2015convolutional, yang2015facial} show that face
detection can be further improved by using deep learning, leveraging the high
capacity of deep convolutional networks.

Considering a more pragmatic approach, the following tips are useful when
selecting a face detection method~\cite{pyimage-face-bestpractices}:
\begin{enum-c}
\item \emph{OpenCV's Haar cascades}:
      Use OpenCV's Haar cascades when speed is your primary concern (e.g., when
      you're using an embedded device like the Raspberry Pi). Haar cascades
      aren't as accurate as their HOG + Linear SVM and deep learning-based
      counterparts, but they make up for it in raw speed. Just be aware there
      will certainly be some false-positive detections and parameter tuning
      required when calling detectMultiScale.
\item \emph{HOG + linear SVM detector}:
    Use dlib's HOG + Linear SVM detector when Haar cascades are not accurate
    enough, but you cannot commit to the computational requirements of a deep
    learning-based face detector. The HOG + Linear SVM object detector is a
    classic algorithm in the computer vision literature that is still relevant
    today. The dlib library does a fantastic job implementing it. Just be aware
    that running HOG + Linear SVM on a CPU will likely be too slow for your
    embedded device.
  \item \emph{CNN face detection}:
    Use dlib's CNN face detection when you need super-accurate face
    detections.
   However, there is a tradeoff — with
    higher accuracy comes slower run-time. This method cannot run in real-time
    on a laptop/desktop CPU, and even with GPU acceleration, you'll struggle to
    hit real-time performance.
  \item \emph{DNN face detector}:
    Use OpenCV's DNN face detector as a good balance. As a deep learning-based
    face detector, this method is accurate — and since it's a shallow network
    with an SSD backbone, it's easily capable of running in real-time on a
    CPU. Furthermore, since you can use the model with OpenCV's cv2.dnn module,
    that also implies that (1) you can increase speed further by using a GPU or
    (2) utilizing the Movidius NCS on your embedded device.
\end{enum-c}

% src: https://www.one-tab.com/page/1OS-OWq1RSKsGPIIvOj2JQ
%\subsubsection{Histogram of Oriented Gradients}
%\label{sec:hist-orient-grad}
%Deep learning methods for face detection can improve the face detection
%accuracy, but they require vast computational resources, making them unpractical
%for real-time detection. Viola-Jones detectors are extremely fast, but not
%reliable. As a trade-off between accuracy and speed, arises the \gls{hog}
%algorithm. Additionally, this algorithm comes built-in the major computer vision
%frameworks.


\subsection{Hand gesture recognition}
\label{sec:hand-gest-recogn}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../../dissertation"
%%% End:
